{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13940920,"sourceType":"datasetVersion","datasetId":8884758}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Freestyle Track ‚Äì PDF Question-Answering Agent (Google √ó Kaggle 5-Day AI Agents Intensive Capstone)\n\nThis project implements a **PDF Question-Answering Agent** powered by Google's Gemini models.\n\n**Track:** Freestyle  \n**Agent goal:** Read a PDF and answer questions grounded only in that document.\n\n**Key agent concepts demonstrated:**\n\n1. **LLM-powered agent** (Gemini as the reasoning engine)  \n2. **Tools** (custom PDF loading tool)  \n3. **Sequential / loop agent** (multi-turn Q&A over the same PDF)  \n4. **Sessions & memory** (chat history across questions)  \n5. **Observability** (logging key steps in the agent)  \n6. **Agent evaluation** (LLM-based scoring of the agent's answers)  \n","metadata":{}},{"cell_type":"code","source":"!pip install -q -U google-genai\n\nfrom google import genai\nfrom google.genai import types\nfrom kaggle_secrets import UserSecretsClient\n\n# Get API key from Kaggle Secrets (Add-ons ‚ûú Secrets ‚ûú GOOGLE_API_KEY)\nuser_secrets = UserSecretsClient()\nGOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n\n# Choose a model ‚Äì you can adjust based on your access\nLLM_MODEL = \"gemini-2.5-flash\"  # fallback: \"gemini-2.0-flash\" or \"gemini-1.5-flash\"\n\nprint(\"Gemini client initialized ‚úÖ\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:38:00.304497Z","iopub.execute_input":"2025-12-01T06:38:00.305355Z","iopub.status.idle":"2025-12-01T06:38:04.746594Z","shell.execute_reply.started":"2025-12-01T06:38:00.305325Z","shell.execute_reply":"2025-12-01T06:38:04.745229Z"}},"outputs":[{"name":"stdout","text":"Gemini client initialized ‚úÖ\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"import logging\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n)\n\nlogging.info(\"Logging initialized for the PDF Q&A Agent.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:38:04.756949Z","iopub.execute_input":"2025-12-01T06:38:04.757401Z","iopub.status.idle":"2025-12-01T06:38:04.764905Z","shell.execute_reply.started":"2025-12-01T06:38:04.757364Z","shell.execute_reply":"2025-12-01T06:38:04.763920Z"}},"outputs":[{"name":"stderr","text":"2025-12-01 06:38:04,759 - INFO - Logging initialized for the PDF Q&A Agent.\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"from pathlib import Path\nfrom google.genai import types\nimport logging\n\n# Path to your PDF (use your dataset and filename)\nPDF_PATH = \"/kaggle/input/dummy-resume/Dummy_resume.pdf\"\n\ndef load_pdf_tool(pdf_path: str) -> types.Part:\n    \"\"\"\n    Custom Tool: Load a PDF from disk and convert it into a Gemini Part.\n    This tool allows the agent to read your PDF content.\n    \"\"\"\n    logging.info(\"Loading PDF from: %s\", pdf_path)\n    pdf_bytes = Path(pdf_path).read_bytes()\n\n    # Convert to Part for Gemini\n    pdf_part = types.Part.from_bytes(\n        data=pdf_bytes,\n        mime_type=\"application/pdf\"\n    )\n\n    logging.info(\"PDF loaded successfully into Gemini Part.\")\n    return pdf_part\n\n\n# Load it now\npdf_part = load_pdf_tool(PDF_PATH)\nprint(\"PDF loaded as Gemini Part ‚úîÔ∏è\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:38:04.766136Z","iopub.execute_input":"2025-12-01T06:38:04.766432Z","iopub.status.idle":"2025-12-01T06:38:04.791990Z","shell.execute_reply.started":"2025-12-01T06:38:04.766411Z","shell.execute_reply":"2025-12-01T06:38:04.790768Z"}},"outputs":[{"name":"stderr","text":"2025-12-01 06:38:04,782 - INFO - Loading PDF from: /kaggle/input/dummy-resume/Dummy_resume.pdf\n2025-12-01 06:38:04,786 - INFO - PDF loaded successfully into Gemini Part.\n","output_type":"stream"},{"name":"stdout","text":"PDF loaded as Gemini Part ‚úîÔ∏è\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"from typing import List, Dict\nimport logging\n\ndef pdf_qa_agent(\n    question: str,\n    pdf_doc: types.Part,\n    chat_history: List[Dict[str, str]] | None = None,\n) -> Dict[str, object]:\n    \"\"\"\n    PDF Question-Answering Agent.\n\n    Inputs:\n      - question: user question in natural language\n      - pdf_doc: Gemini Part containing the PDF\n      - chat_history: optional list of previous turns: {'role': 'user'/'agent', 'content': str}\n\n    Returns:\n      - dict with keys: 'answer' (str), 'updated_history' (list)\n    \"\"\"\n    logging.info(\"Agent received question: %s\", question)\n\n    if chat_history is None:\n        chat_history = []\n\n    # --- Session & Memory: build compact context from recent history ---\n    history_text = \"\"\n    if chat_history:\n        logging.info(\"Building context from chat history with %d messages.\", len(chat_history))\n        lines = []\n        # keep only the last few turns (simple context compaction)\n        for turn in chat_history[-6:]:\n            role = turn[\"role\"]\n            content = turn[\"content\"]\n            lines.append(f\"{role.upper()}: {content}\")\n        history_text = \"Previous conversation:\\n\" + \"\\n\".join(lines)\n\n    # --- System instruction: how the agent should behave ---\n    system_instruction = (\n        \"You are a helpful PDF question-answering agent. \"\n        \"You must answer ONLY using information from the attached PDF (the user's resume). \"\n        \"If the answer is not in the document, say you do not know. \"\n        \"Be concise and, when helpful, mention where in the resume you found the info \"\n        \"like 'In the experience section' or 'Under skills'.\"\n    )\n\n    contents = [system_instruction]\n\n    if history_text:\n        contents.append(history_text)\n\n    # Attach the PDF and the current question\n    contents.append(pdf_doc)\n    contents.append(f\"Question: {question}\")\n\n    logging.info(\"Calling Gemini model: %s\", LLM_MODEL)\n    response = client.models.generate_content(\n        model=LLM_MODEL,\n        contents=contents,\n    )\n\n    answer_text = response.text\n    logging.info(\"Model returned an answer of length %d characters.\", len(answer_text))\n\n    # --- Update chat history (session memory) ---\n    new_history = chat_history + [\n        {\"role\": \"user\", \"content\": question},\n        {\"role\": \"agent\", \"content\": answer_text},\n    ]\n\n    return {\n        \"answer\": answer_text,\n        \"updated_history\": new_history,\n    }\n\nprint(\"PDF Q&A Agent defined üöÄ\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:38:04.793134Z","iopub.execute_input":"2025-12-01T06:38:04.793409Z","iopub.status.idle":"2025-12-01T06:38:04.816387Z","shell.execute_reply.started":"2025-12-01T06:38:04.793378Z","shell.execute_reply":"2025-12-01T06:38:04.815287Z"}},"outputs":[{"name":"stdout","text":"PDF Q&A Agent defined üöÄ\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"chat_history = []\n\nquestions = [\n    \"Give me a short summary of this resume in 4-5 bullet points.\",\n    \"List all the skills mentioned in the resume.\",\n    \"What work experience does the resume describe?\",\n]\n\nfor idx, q in enumerate(questions, start=1):\n    logging.info(\"Running test question %d\", idx)\n    result = pdf_qa_agent(\n        question=q,\n        pdf_doc=pdf_part,\n        chat_history=chat_history,\n    )\n    chat_history = result[\"updated_history\"]\n\n    print(f\"\\n=== Question {idx} ===\")\n    print(\"Q:\", q)\n    print(\"\\nAgent answer:\\n\", result[\"answer\"])\n    print(\"=\" * 60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:38:04.819135Z","iopub.execute_input":"2025-12-01T06:38:04.819632Z","iopub.status.idle":"2025-12-01T06:38:15.049084Z","shell.execute_reply.started":"2025-12-01T06:38:04.819603Z","shell.execute_reply":"2025-12-01T06:38:15.047938Z"}},"outputs":[{"name":"stderr","text":"2025-12-01 06:38:04,841 - INFO - Running test question 1\n2025-12-01 06:38:04,842 - INFO - Agent received question: Give me a short summary of this resume in 4-5 bullet points.\n2025-12-01 06:38:04,844 - INFO - Calling Gemini model: gemini-2.5-flash\n2025-12-01 06:38:04,845 - INFO - AFC is enabled with max remote calls: 10.\n2025-12-01 06:38:10,378 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n2025-12-01 06:38:10,382 - INFO - Model returned an answer of length 981 characters.\n2025-12-01 06:38:10,383 - INFO - Running test question 2\n2025-12-01 06:38:10,384 - INFO - Agent received question: List all the skills mentioned in the resume.\n2025-12-01 06:38:10,385 - INFO - Building context from chat history with 2 messages.\n2025-12-01 06:38:10,386 - INFO - Calling Gemini model: gemini-2.5-flash\n2025-12-01 06:38:10,387 - INFO - AFC is enabled with max remote calls: 10.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Question 1 ===\nQ: Give me a short summary of this resume in 4-5 bullet points.\n\nAgent answer:\n Here is a short summary of the resume:\n\n*   John Doe is a Full Stack Developer with experience in JavaScript technologies, frontend, backend, API design, and cloud deployment (from Professional Summary).\n*   He holds a Bachelor of Science in Computer Science from the University of California, Berkeley (2020-2024) (from Education).\n*   His experience includes internships as a Full Stack Developer at TechNova Solutions and a Frontend Developer at CloudByte Labs, where he built APIs, developed reusable components, and optimized performance (from Experience).\n*   He is proficient in languages like JavaScript, Python, and TypeScript, and frameworks/tools such as React, Node.js, MongoDB, Git, and Docker (under Technical Skills).\n*   He has earned a Meta Front-End Developer Certificate and a Google Data Analytics Certificate, and notable achievements include 150+ GitHub contributions in 90 days and a top 3 finish at HackTheFuture 2024 (from Certifications and Achievements).\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"2025-12-01 06:38:12,680 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n2025-12-01 06:38:12,684 - INFO - Model returned an answer of length 316 characters.\n2025-12-01 06:38:12,685 - INFO - Running test question 3\n2025-12-01 06:38:12,686 - INFO - Agent received question: What work experience does the resume describe?\n2025-12-01 06:38:12,687 - INFO - Building context from chat history with 4 messages.\n2025-12-01 06:38:12,687 - INFO - Calling Gemini model: gemini-2.5-flash\n2025-12-01 06:38:12,688 - INFO - AFC is enabled with max remote calls: 10.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Question 2 ===\nQ: List all the skills mentioned in the resume.\n\nAgent answer:\n Here are all the skills mentioned in the resume (under Technical Skills):\n\n*   **Languages:** JavaScript (ES6+), Python, TypeScript\n*   **Frontend:** React, Next.js, Tailwind CSS\n*   **Backend:** Node.js, Express.js, REST APIs\n*   **Databases:** MongoDB, PostgreSQL\n*   **Tools:** Git, Docker, Postman, Jest, VS Code\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"2025-12-01 06:38:15,041 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n2025-12-01 06:38:15,044 - INFO - Model returned an answer of length 250 characters.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Question 3 ===\nQ: What work experience does the resume describe?\n\nAgent answer:\n Here is the work experience described in the resume (from Experience):\n\n*   **TechNova Solutions (Remote):** Full Stack Developer Intern (Jun 2024 - Aug 2024)\n*   **CloudByte Labs (San Francisco, CA):** Frontend Developer Intern (Jan 2024 - Apr 2024)\n============================================================\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"def evaluate_agent_answer(question: str, answer: str) -> str:\n    \"\"\"\n    LLM-based evaluator that rates the agent's answer.\n    This satisfies the 'Agent Evaluation' requirement in the capstone.\n    \"\"\"\n    logging.info(\"Evaluating agent's answer...\")\n\n    eval_prompt = f\"\"\"\nYou are an evaluator for a PDF question-answering agent.\n\nEvaluate the agent's response based on:\n1. Accuracy and correctness based on the PDF.\n2. Clarity and structure.\n3. Whether the answer stays grounded in the document.\n4. Whether it directly answers the question.\n\nGive a score from 1 to 10.\nThen explain the score in 3‚Äì4 lines.\n\n---\n\nQuestion:\n{question}\n\nAgent Answer:\n{answer}\n\"\"\"\n\n    response = client.models.generate_content(\n        model=LLM_MODEL,\n        contents=[eval_prompt],\n    )\n\n    return response.text\n\nprint(\"Evaluation function added ‚úîÔ∏è\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:38:15.050130Z","iopub.execute_input":"2025-12-01T06:38:15.050384Z","iopub.status.idle":"2025-12-01T06:38:15.058949Z","shell.execute_reply.started":"2025-12-01T06:38:15.050355Z","shell.execute_reply":"2025-12-01T06:38:15.057420Z"}},"outputs":[{"name":"stdout","text":"Evaluation function added ‚úîÔ∏è\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"# Extract the last user question and last agent answer from chat_history\nlast_question = None\nlast_answer = None\n\nfor turn in reversed(chat_history):\n    if turn[\"role\"] == \"agent\" and last_answer is None:\n        last_answer = turn[\"content\"]\n    elif turn[\"role\"] == \"user\" and last_question is None:\n        last_question = turn[\"content\"]\n    if last_question and last_answer:\n        break\n\n# If we have both, evaluate the answer\nif last_question and last_answer:\n    print(\"Last Question:\\n\", last_question)\n    print(\"\\nLast Agent Answer:\\n\", last_answer)\n    print(\"\\n------------------ Evaluation ------------------\\n\")\n    eval_result = evaluate_agent_answer(last_question, last_answer)\n    print(eval_result)\nelse:\n    print(\"No Q&A found in chat_history to evaluate.\")\n# Extract the last user question and last agent answer from chat_history\nlast_question = None\nlast_answer = None\n\nfor turn in reversed(chat_history):\n    if turn[\"role\"] == \"agent\" and last_answer is None:\n        last_answer = turn[\"content\"]\n    elif turn[\"role\"] == \"user\" and last_question is None:\n        last_question = turn[\"content\"]\n    if last_question and last_answer:\n        break\n\n# If we have both, evaluate the answer\nif last_question and last_answer:\n    print(\"Last Question:\\n\", last_question)\n    print(\"\\nLast Agent Answer:\\n\", last_answer)\n    print(\"\\n------------------ Evaluation ------------------\\n\")\n    eval_result = evaluate_agent_answer(last_question, last_answer)\n    print(eval_result)\nelse:\n    print(\"No Q&A found in chat_history to evaluate.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:38:15.060677Z","iopub.execute_input":"2025-12-01T06:38:15.061093Z","iopub.status.idle":"2025-12-01T06:38:22.607413Z","shell.execute_reply.started":"2025-12-01T06:38:15.061060Z","shell.execute_reply":"2025-12-01T06:38:22.606452Z"}},"outputs":[{"name":"stderr","text":"2025-12-01 06:38:15,082 - INFO - Evaluating agent's answer...\n2025-12-01 06:38:15,084 - INFO - AFC is enabled with max remote calls: 10.\n","output_type":"stream"},{"name":"stdout","text":"Last Question:\n What work experience does the resume describe?\n\nLast Agent Answer:\n Here is the work experience described in the resume (from Experience):\n\n*   **TechNova Solutions (Remote):** Full Stack Developer Intern (Jun 2024 - Aug 2024)\n*   **CloudByte Labs (San Francisco, CA):** Frontend Developer Intern (Jan 2024 - Apr 2024)\n\n------------------ Evaluation ------------------\n\n","output_type":"stream"},{"name":"stderr","text":"2025-12-01 06:38:18,117 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n2025-12-01 06:38:18,120 - INFO - Evaluating agent's answer...\n2025-12-01 06:38:18,121 - INFO - AFC is enabled with max remote calls: 10.\n","output_type":"stream"},{"name":"stdout","text":"Score: 10\n\nThe agent accurately extracts and presents all relevant work experience from the resume. The answer is clear, well-structured using bullet points, and directly addresses the question without adding extraneous information. It demonstrates excellent grounding in the document by providing specific details like roles, companies, locations, and dates.\nLast Question:\n What work experience does the resume describe?\n\nLast Agent Answer:\n Here is the work experience described in the resume (from Experience):\n\n*   **TechNova Solutions (Remote):** Full Stack Developer Intern (Jun 2024 - Aug 2024)\n*   **CloudByte Labs (San Francisco, CA):** Frontend Developer Intern (Jan 2024 - Apr 2024)\n\n------------------ Evaluation ------------------\n\n","output_type":"stream"},{"name":"stderr","text":"2025-12-01 06:38:22,600 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n","output_type":"stream"},{"name":"stdout","text":"Score: 10\n\nThe agent accurately extracts and presents the work experience directly from the resume, using a clear and well-structured bullet-point format. It includes all relevant details like company, role, location, and dates for each entry, making it easy to read and understand. The answer directly addresses the question and stays entirely grounded in the document's content.\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"def ask_agent(question: str):\n    \"\"\"\n    A helper function to manually ask questions to the agent.\n    Keeps memory and logs everything.\n    \"\"\"\n    global chat_history\n    logging.info(\"Manual question asked: %s\", question)\n\n    result = pdf_qa_agent(\n        question=question,\n        pdf_doc=pdf_part,\n        chat_history=chat_history\n    )\n    chat_history = result[\"updated_history\"]\n\n    print(\"\\nQ:\", question)\n    print(\"\\nAgent:\\n\", result[\"answer\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:38:22.608878Z","iopub.execute_input":"2025-12-01T06:38:22.609120Z","iopub.status.idle":"2025-12-01T06:38:22.616101Z","shell.execute_reply.started":"2025-12-01T06:38:22.609100Z","shell.execute_reply":"2025-12-01T06:38:22.615141Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"ask_agent(\"Explain my resume as if I am a beginner who doesn‚Äôt know technical terms.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:38:22.617035Z","iopub.execute_input":"2025-12-01T06:38:22.617272Z","iopub.status.idle":"2025-12-01T06:38:30.712306Z","shell.execute_reply.started":"2025-12-01T06:38:22.617252Z","shell.execute_reply":"2025-12-01T06:38:30.711275Z"}},"outputs":[{"name":"stderr","text":"2025-12-01 06:38:22,636 - INFO - Manual question asked: Explain my resume as if I am a beginner who doesn‚Äôt know technical terms.\n2025-12-01 06:38:22,637 - INFO - Agent received question: Explain my resume as if I am a beginner who doesn‚Äôt know technical terms.\n2025-12-01 06:38:22,639 - INFO - Building context from chat history with 6 messages.\n2025-12-01 06:38:22,639 - INFO - Calling Gemini model: gemini-2.5-flash\n2025-12-01 06:38:22,640 - INFO - AFC is enabled with max remote calls: 10.\n2025-12-01 06:38:30,705 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n2025-12-01 06:38:30,708 - INFO - Model returned an answer of length 3837 characters.\n","output_type":"stream"},{"name":"stdout","text":"\nQ: Explain my resume as if I am a beginner who doesn‚Äôt know technical terms.\n\nAgent:\n Okay, let's break down your resume into simpler terms, imagining you're explaining it to someone who's new to tech:\n\nHere's your resume, explained:\n\n*   **Who you are (Professional Summary):** You're like a master builder for websites and apps. You're good at making both the parts users see (the \"frontend\") and the hidden machinery that makes everything work behind the scenes (the \"backend\"). You're good at designing how different parts of an app talk to each other (\"API design\"), and how to put apps online (\"cloud deployment\"). You care about making things work well, look good, and be easy for people to use.\n\n*   **Your Schooling (Education):** You went to a big university, UC Berkeley, and got a degree in Computer Science, which is basically the study of how computers and software work. You also have a high school diploma.\n\n*   **Your Work Experience (Experience):**\n    *   **TechNova Solutions (Intern):** You worked as an intern, building both the visible parts and the hidden systems for apps. You created the \"backbone\" of apps that made them 20% faster. You also built parts of apps that 5,000+ people used every month, made sure people could log in securely, and wrote special checks to catch problems in the user-facing parts of apps, which reduced errors by 30%.\n    *   **CloudByte Labs (Intern):** You focused on the parts of apps that users see. You built flexible pieces for the app's look and feel, and made the app much faster and smoother (improving its \"Lighthouse score\" from 68 to 92). You made sure the app looked good and worked well on phones and computers, and connected the app to data that helped understand how it was being used.\n\n*   **Things You've Built (Key Projects):**\n    *   **SmartTask Productivity App:** You made a complete app to help people manage their tasks, including reminders and dashboards to see progress. You built in features for users to sign up and manage their own data.\n    *   **AI Recipe Finder:** You created an app that uses artificial intelligence (AI) to suggest recipes based on what you tell it. It can even recognize ingredients and give you step-by-step cooking instructions.\n\n*   **Special Certificates (Certifications):** You've completed official training and earned certificates in making user-facing parts of apps (Meta Front-End Developer Certificate) and in understanding data (Google Data Analytics Certificate).\n\n*   **Your Toolkit (Technical Skills):**\n    *   **Languages:** These are the \"programming languages\" you speak to computers, like JavaScript (a very common one for web), Python (good for many things, including AI), and TypeScript (a more organized version of JavaScript).\n    *   **Frontend:** These are the tools you use to build what users see and interact with, like React (a popular way to build interactive web pages), Next.js (for more advanced web apps), and Tailwind CSS (to style how things look).\n    *   **Backend:** These are tools for the hidden parts of apps, like Node.js and Express.js (to power the server that runs the app), and REST APIs (the rules for how different parts of apps talk to each other).\n    *   **Databases:** These are systems where you store information for apps, like MongoDB and PostgreSQL.\n    *   **Tools:** These are other helpful utilities you use, like Git (for teamwork and tracking changes in code), Docker (to package apps so they run anywhere), Postman (to test APIs), Jest (to test code), and VS Code (your main writing tool for code).\n\n*   **Cool Things You've Done (Achievements):**\n    *   You're very active on GitHub (a place where developers share code), making over 150 contributions in just 3 months.\n    *   You competed in a coding challenge called HackTheFuture 2024 and your team finished in the top 3!\n\n(All information found throughout the resume, categorized and simplified.)\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"ask_agent(\"What job roles am I most suitable for based on my resume?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:38:30.713457Z","iopub.execute_input":"2025-12-01T06:38:30.713711Z","iopub.status.idle":"2025-12-01T06:38:33.964577Z","shell.execute_reply.started":"2025-12-01T06:38:30.713689Z","shell.execute_reply":"2025-12-01T06:38:33.963602Z"}},"outputs":[{"name":"stderr","text":"2025-12-01 06:38:30,714 - INFO - Manual question asked: What job roles am I most suitable for based on my resume?\n2025-12-01 06:38:30,716 - INFO - Agent received question: What job roles am I most suitable for based on my resume?\n2025-12-01 06:38:30,717 - INFO - Building context from chat history with 8 messages.\n2025-12-01 06:38:30,718 - INFO - Calling Gemini model: gemini-2.5-flash\n2025-12-01 06:38:30,719 - INFO - AFC is enabled with max remote calls: 10.\n2025-12-01 06:38:33,956 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n2025-12-01 06:38:33,959 - INFO - Model returned an answer of length 423 characters.\n","output_type":"stream"},{"name":"stdout","text":"\nQ: What job roles am I most suitable for based on my resume?\n\nAgent:\n Based on your resume, you are most suitable for the following job roles:\n\n*   **Full Stack Developer** (mentioned in Professional Summary and Experience, and implied by Key Projects)\n*   **Frontend Developer** (mentioned in Professional Summary and Experience, and supported by Certifications and Technical Skills)\n\nYour resume also highlights skills in API design and cloud deployment, which are components of these roles.\n","output_type":"stream"}],"execution_count":58},{"cell_type":"markdown","source":"# üìÑ Freestyle Track ‚Äì PDF Question-Answering Agent (AI Agents Intensive Capstone)\n\nThis project implements a **PDF Question-Answering Agent** using Google Gemini models.  \nThe agent reads a PDF (my resume) and answers questions based only on the content of that document.\n\n---\n\n# üéØ Goal of the Agent\nThe agent‚Äôs goal is to:\n- Load and analyze a PDF document.\n- Answer questions in natural language.\n- Stay grounded strictly in the PDF content.\n- Maintain memory across multiple questions.\n- Provide clear, structured responses.\n\n---\n\n# ü§ñ Key Agent Concepts Demonstrated\n\n## 1. **LLM-Powered Agent**\nThe core function `pdf_qa_agent()` uses a Gemini model as the reasoning engine.  \nThe agent understands queries, analyzes the PDF, and generates grounded answers.\n\n---\n\n## 2. **Custom Tool Usage**\nI implemented a **custom tool**:\n\n`load_pdf_tool(pdf_path)`\n\nThis tool:\n- Reads a PDF from Kaggle input directory.\n- Converts it into a Gemini-compatible `Part`.\n- Allows the agent to ‚Äúsee‚Äù and process the resume.\n\n---\n\n## 3. **Sequential Agent / Loop Behavior**\nThe agent handles multi-step interactions:\n- I asked 3 test questions in sequence.\n- The agent answered each one using the PDF.\n- The agent maintained memory across turns.\n\nThis demonstrates sequential agent workflow.\n\n---\n\n## 4. **Sessions & Memory**\nThe agent stores conversation turns using `chat_history`.  \nMemory is compacted (only the last few turns kept) to improve context efficiency.\n\nThis enables:\n- Follow-up questions\n- Multi-turn reasoning\n- Improved contextual grounding\n\n---\n\n## 5. **Observability (Logging)**\nI added Python `logging` to track:\n- When the agent receives questions\n- When the PDF loads\n- When the model is called\n- When answers are returned\n- When evaluations occur\n\nThis provides transparency into the agent‚Äôs execution.\n\n---\n\n## 6. **Agent Evaluation**\nThe function `evaluate_agent_answer()`:\n- Uses Gemini to evaluate the agent‚Äôs response\n- Scores the answer on accuracy, clarity, PDF grounding\n- Provides reasoning for the score\n\nThis satisfies the ‚ÄúAgent Evaluation‚Äù requirement.\n\n---\n\n# üìä Results\n- The agent successfully analyzed my resume.\n- It answered:  \n  - Summary  \n  - Skills  \n  - Work experience  \n- The evaluation gave the agent a **10/10 score**, indicating:\n  - High accuracy  \n  - Grounded responses  \n  - Clear structure  \n\n---\n\n# üöÄ Conclusion\n\nThis capstone demonstrates a complete **Freestyle AI Agent** applying key concepts taught in the Google √ó Kaggle 5-Day AI Agents Intensive Course:\n\n‚úîÔ∏è LLM agent  \n‚úîÔ∏è Tools (custom tool)  \n‚úîÔ∏è Memory  \n‚úîÔ∏è Sequential agent behavior  \n‚úîÔ∏è Observability (logging)  \n‚úîÔ∏è Agent evaluation  \n\nThe result is a functional, extendable PDF Q&A assistant that can be improved with features like RAG, multi-agent workflows, or a user interface.\n\n","metadata":{}}]}