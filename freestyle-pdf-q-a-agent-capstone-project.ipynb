{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13939648,"sourceType":"datasetVersion","datasetId":8883787}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Freestyle Track ‚Äì PDF Question-Answering Agent (Google √ó Kaggle 5-Day AI Agents Intensive Capstone)\n\nThis project implements a **PDF Question-Answering Agent** powered by Google's Gemini models.\n\n**Track:** Freestyle  \n**Agent goal:** Read a PDF and answer questions grounded only in that document.\n\n**Key agent concepts demonstrated:**\n\n1. **LLM-powered agent** (Gemini as the reasoning engine)  \n2. **Tools** (custom PDF loading tool)  \n3. **Sequential / loop agent** (multi-turn Q&A over the same PDF)  \n4. **Sessions & memory** (chat history across questions)  \n5. **Observability** (logging key steps in the agent)  \n6. **Agent evaluation** (LLM-based scoring of the agent's answers)  \n","metadata":{}},{"cell_type":"code","source":"!pip install -q -U google-genai\n\nfrom google import genai\nfrom google.genai import types\nfrom kaggle_secrets import UserSecretsClient\n\n# Get API key from Kaggle Secrets (Add-ons ‚ûú Secrets ‚ûú GOOGLE_API_KEY)\nuser_secrets = UserSecretsClient()\nGOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n\n# Choose a model ‚Äì you can adjust based on your access\nLLM_MODEL = \"gemini-2.5-flash\"  # fallback: \"gemini-2.0-flash\" or \"gemini-1.5-flash\"\n\nprint(\"Gemini client initialized ‚úÖ\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:50:21.113486Z","iopub.execute_input":"2025-12-01T05:50:21.114126Z","iopub.status.idle":"2025-12-01T05:50:25.738095Z","shell.execute_reply.started":"2025-12-01T05:50:21.114083Z","shell.execute_reply":"2025-12-01T05:50:25.736826Z"}},"outputs":[{"name":"stdout","text":"Gemini client initialized ‚úÖ\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import logging\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n)\n\nlogging.info(\"Logging initialized for the PDF Q&A Agent.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:50:25.781774Z","iopub.execute_input":"2025-12-01T05:50:25.782177Z","iopub.status.idle":"2025-12-01T05:50:25.791098Z","shell.execute_reply.started":"2025-12-01T05:50:25.782144Z","shell.execute_reply":"2025-12-01T05:50:25.789615Z"}},"outputs":[{"name":"stderr","text":"2025-12-01 05:50:25,784 - INFO - Logging initialized for the PDF Q&A Agent.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from pathlib import Path\nfrom google.genai import types\nimport logging\n\n# Path to your PDF (use your dataset and filename)\nPDF_PATH = \"/kaggle/input/document-analysis/MohseenAliHawaldar.pdf\"\n\ndef load_pdf_tool(pdf_path: str) -> types.Part:\n    \"\"\"\n    Custom Tool: Load a PDF from disk and convert it into a Gemini Part.\n    This tool allows the agent to read your PDF content.\n    \"\"\"\n    logging.info(\"Loading PDF from: %s\", pdf_path)\n    pdf_bytes = Path(pdf_path).read_bytes()\n\n    # Convert to Part for Gemini\n    pdf_part = types.Part.from_bytes(\n        data=pdf_bytes,\n        mime_type=\"application/pdf\"\n    )\n\n    logging.info(\"PDF loaded successfully into Gemini Part.\")\n    return pdf_part\n\n\n# Load it now\npdf_part = load_pdf_tool(PDF_PATH)\nprint(\"PDF loaded as Gemini Part ‚úîÔ∏è\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:50:25.792736Z","iopub.execute_input":"2025-12-01T05:50:25.793183Z","iopub.status.idle":"2025-12-01T05:50:25.828627Z","shell.execute_reply.started":"2025-12-01T05:50:25.793145Z","shell.execute_reply":"2025-12-01T05:50:25.827375Z"}},"outputs":[{"name":"stderr","text":"2025-12-01 05:50:25,811 - INFO - Loading PDF from: /kaggle/input/document-analysis/MohseenAliHawaldar.pdf\n2025-12-01 05:50:25,823 - INFO - PDF loaded successfully into Gemini Part.\n","output_type":"stream"},{"name":"stdout","text":"PDF loaded as Gemini Part ‚úîÔ∏è\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from typing import List, Dict\nimport logging\n\ndef pdf_qa_agent(\n    question: str,\n    pdf_doc: types.Part,\n    chat_history: List[Dict[str, str]] | None = None,\n) -> Dict[str, object]:\n    \"\"\"\n    PDF Question-Answering Agent.\n\n    Inputs:\n      - question: user question in natural language\n      - pdf_doc: Gemini Part containing the PDF\n      - chat_history: optional list of previous turns: {'role': 'user'/'agent', 'content': str}\n\n    Returns:\n      - dict with keys: 'answer' (str), 'updated_history' (list)\n    \"\"\"\n    logging.info(\"Agent received question: %s\", question)\n\n    if chat_history is None:\n        chat_history = []\n\n    # --- Session & Memory: build compact context from recent history ---\n    history_text = \"\"\n    if chat_history:\n        logging.info(\"Building context from chat history with %d messages.\", len(chat_history))\n        lines = []\n        # keep only the last few turns (simple context compaction)\n        for turn in chat_history[-6:]:\n            role = turn[\"role\"]\n            content = turn[\"content\"]\n            lines.append(f\"{role.upper()}: {content}\")\n        history_text = \"Previous conversation:\\n\" + \"\\n\".join(lines)\n\n    # --- System instruction: how the agent should behave ---\n    system_instruction = (\n        \"You are a helpful PDF question-answering agent. \"\n        \"You must answer ONLY using information from the attached PDF (the user's resume). \"\n        \"If the answer is not in the document, say you do not know. \"\n        \"Be concise and, when helpful, mention where in the resume you found the info \"\n        \"like 'In the experience section' or 'Under skills'.\"\n    )\n\n    contents = [system_instruction]\n\n    if history_text:\n        contents.append(history_text)\n\n    # Attach the PDF and the current question\n    contents.append(pdf_doc)\n    contents.append(f\"Question: {question}\")\n\n    logging.info(\"Calling Gemini model: %s\", LLM_MODEL)\n    response = client.models.generate_content(\n        model=LLM_MODEL,\n        contents=contents,\n    )\n\n    answer_text = response.text\n    logging.info(\"Model returned an answer of length %d characters.\", len(answer_text))\n\n    # --- Update chat history (session memory) ---\n    new_history = chat_history + [\n        {\"role\": \"user\", \"content\": question},\n        {\"role\": \"agent\", \"content\": answer_text},\n    ]\n\n    return {\n        \"answer\": answer_text,\n        \"updated_history\": new_history,\n    }\n\nprint(\"PDF Q&A Agent defined üöÄ\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:50:25.830118Z","iopub.execute_input":"2025-12-01T05:50:25.830459Z","iopub.status.idle":"2025-12-01T05:50:25.846646Z","shell.execute_reply.started":"2025-12-01T05:50:25.830432Z","shell.execute_reply":"2025-12-01T05:50:25.845544Z"}},"outputs":[{"name":"stdout","text":"PDF Q&A Agent defined üöÄ\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"chat_history = []\n\nquestions = [\n    \"Give me a short summary of this resume in 4-5 bullet points.\",\n    \"List all the skills mentioned in the resume.\",\n    \"What work experience does the resume describe?\",\n]\n\nfor idx, q in enumerate(questions, start=1):\n    logging.info(\"Running test question %d\", idx)\n    result = pdf_qa_agent(\n        question=q,\n        pdf_doc=pdf_part,\n        chat_history=chat_history,\n    )\n    chat_history = result[\"updated_history\"]\n\n    print(f\"\\n=== Question {idx} ===\")\n    print(\"Q:\", q)\n    print(\"\\nAgent answer:\\n\", result[\"answer\"])\n    print(\"=\" * 60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:50:25.848988Z","iopub.execute_input":"2025-12-01T05:50:25.849273Z","iopub.status.idle":"2025-12-01T05:50:35.200181Z","shell.execute_reply.started":"2025-12-01T05:50:25.849249Z","shell.execute_reply":"2025-12-01T05:50:35.199082Z"}},"outputs":[{"name":"stderr","text":"2025-12-01 05:50:25,869 - INFO - Running test question 1\n2025-12-01 05:50:25,871 - INFO - Agent received question: Give me a short summary of this resume in 4-5 bullet points.\n2025-12-01 05:50:25,872 - INFO - Calling Gemini model: gemini-2.5-flash\n2025-12-01 05:50:25,874 - INFO - AFC is enabled with max remote calls: 10.\n2025-12-01 05:50:30,431 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n2025-12-01 05:50:30,436 - INFO - Model returned an answer of length 656 characters.\n2025-12-01 05:50:30,437 - INFO - Running test question 2\n2025-12-01 05:50:30,437 - INFO - Agent received question: List all the skills mentioned in the resume.\n2025-12-01 05:50:30,438 - INFO - Building context from chat history with 2 messages.\n2025-12-01 05:50:30,439 - INFO - Calling Gemini model: gemini-2.5-flash\n2025-12-01 05:50:30,440 - INFO - AFC is enabled with max remote calls: 10.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Question 1 ===\nQ: Give me a short summary of this resume in 4-5 bullet points.\n\nAgent answer:\n Here's a short summary of the resume:\n\n*   Full Stack Developer with experience in the MERN stack and modern UI frameworks. (In the Professional Summary)\n*   Holds a Bachelor of Engineering in Computer Science and Engineering (expected Jun 2026). (Under Education)\n*   Completed internships as a Full Stack Developer Intern at Codec Technologies and a Front-End Software Engineering Intern at Skyscanner. (Under Experience)\n*   Proficient in languages like JavaScript, Python, Java, and SQL, and frameworks such as React, Node.js, and Express.js. (Under Technical Skills)\n*   Achieved over 90 GitHub contributions in the last 3 months. (Under Achievements)\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"2025-12-01 05:50:32,748 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n2025-12-01 05:50:32,751 - INFO - Model returned an answer of length 346 characters.\n2025-12-01 05:50:32,752 - INFO - Running test question 3\n2025-12-01 05:50:32,753 - INFO - Agent received question: What work experience does the resume describe?\n2025-12-01 05:50:32,754 - INFO - Building context from chat history with 4 messages.\n2025-12-01 05:50:32,754 - INFO - Calling Gemini model: gemini-2.5-flash\n2025-12-01 05:50:32,755 - INFO - AFC is enabled with max remote calls: 10.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Question 2 ===\nQ: List all the skills mentioned in the resume.\n\nAgent answer:\n Here are the skills mentioned in the resume:\n\n*   **Languages:** JavaScript (ES6+), Python, Java, SQL (Under Technical Skills)\n*   **Frameworks and Libraries:** React, Node.js, Express.js, Redux, Tailwind CSS, Framer Motion (Under Technical Skills)\n*   **Database and Tools:** MongoDB, Git, Docker, Postman, Jest, VS Code (Under Technical Skills)\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"2025-12-01 05:50:35,192 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n2025-12-01 05:50:35,195 - INFO - Model returned an answer of length 767 characters.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Question 3 ===\nQ: What work experience does the resume describe?\n\nAgent answer:\n The resume describes the following work experience:\n\n*   **Full Stack Developer Intern** at Codec Technologies, Pune, Maharashtra (Virtual) from Jan 2025 to Feb 2025. In this role, the individual engineered web solutions using the MERN Stack, built secure RESTful APIs with JWT Authentication and RBAC, optimized MongoDB queries, and collaborated on debugging issues using MVC architecture. (Under Experience)\n*   **Front-End Software Engineering Intern** at Skyscanner, Virtual from Sep 2025 to Oct 2025. Responsibilities included developing a high-traffic travel date-picker component using React, writing automated tests using Jest, enhancing frontend performance with code splitting, and ensuring cross-browser compatibility and WCAG adherence. (Under Experience)\n============================================================\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def evaluate_agent_answer(question: str, answer: str) -> str:\n    \"\"\"\n    LLM-based evaluator that rates the agent's answer.\n    This satisfies the 'Agent Evaluation' requirement in the capstone.\n    \"\"\"\n    logging.info(\"Evaluating agent's answer...\")\n\n    eval_prompt = f\"\"\"\nYou are an evaluator for a PDF question-answering agent.\n\nEvaluate the agent's response based on:\n1. Accuracy and correctness based on the PDF.\n2. Clarity and structure.\n3. Whether the answer stays grounded in the document.\n4. Whether it directly answers the question.\n\nGive a score from 1 to 10.\nThen explain the score in 3‚Äì4 lines.\n\n---\n\nQuestion:\n{question}\n\nAgent Answer:\n{answer}\n\"\"\"\n\n    response = client.models.generate_content(\n        model=LLM_MODEL,\n        contents=[eval_prompt],\n    )\n\n    return response.text\n\nprint(\"Evaluation function added ‚úîÔ∏è\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:50:35.201325Z","iopub.execute_input":"2025-12-01T05:50:35.201660Z","iopub.status.idle":"2025-12-01T05:50:35.209124Z","shell.execute_reply.started":"2025-12-01T05:50:35.201626Z","shell.execute_reply":"2025-12-01T05:50:35.207952Z"}},"outputs":[{"name":"stdout","text":"Evaluation function added ‚úîÔ∏è\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Extract the last user question and last agent answer from chat_history\nlast_question = None\nlast_answer = None\n\nfor turn in reversed(chat_history):\n    if turn[\"role\"] == \"agent\" and last_answer is None:\n        last_answer = turn[\"content\"]\n    elif turn[\"role\"] == \"user\" and last_question is None:\n        last_question = turn[\"content\"]\n    if last_question and last_answer:\n        break\n\n# If we have both, evaluate the answer\nif last_question and last_answer:\n    print(\"Last Question:\\n\", last_question)\n    print(\"\\nLast Agent Answer:\\n\", last_answer)\n    print(\"\\n------------------ Evaluation ------------------\\n\")\n    eval_result = evaluate_agent_answer(last_question, last_answer)\n    print(eval_result)\nelse:\n    print(\"No Q&A found in chat_history to evaluate.\")\n# Extract the last user question and last agent answer from chat_history\nlast_question = None\nlast_answer = None\n\nfor turn in reversed(chat_history):\n    if turn[\"role\"] == \"agent\" and last_answer is None:\n        last_answer = turn[\"content\"]\n    elif turn[\"role\"] == \"user\" and last_question is None:\n        last_question = turn[\"content\"]\n    if last_question and last_answer:\n        break\n\n# If we have both, evaluate the answer\nif last_question and last_answer:\n    print(\"Last Question:\\n\", last_question)\n    print(\"\\nLast Agent Answer:\\n\", last_answer)\n    print(\"\\n------------------ Evaluation ------------------\\n\")\n    eval_result = evaluate_agent_answer(last_question, last_answer)\n    print(eval_result)\nelse:\n    print(\"No Q&A found in chat_history to evaluate.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:50:35.210262Z","iopub.execute_input":"2025-12-01T05:50:35.210572Z","iopub.status.idle":"2025-12-01T05:50:43.531502Z","shell.execute_reply.started":"2025-12-01T05:50:35.210540Z","shell.execute_reply":"2025-12-01T05:50:43.530155Z"}},"outputs":[{"name":"stderr","text":"2025-12-01 05:50:35,232 - INFO - Evaluating agent's answer...\n2025-12-01 05:50:35,233 - INFO - AFC is enabled with max remote calls: 10.\n","output_type":"stream"},{"name":"stdout","text":"Last Question:\n What work experience does the resume describe?\n\nLast Agent Answer:\n The resume describes the following work experience:\n\n*   **Full Stack Developer Intern** at Codec Technologies, Pune, Maharashtra (Virtual) from Jan 2025 to Feb 2025. In this role, the individual engineered web solutions using the MERN Stack, built secure RESTful APIs with JWT Authentication and RBAC, optimized MongoDB queries, and collaborated on debugging issues using MVC architecture. (Under Experience)\n*   **Front-End Software Engineering Intern** at Skyscanner, Virtual from Sep 2025 to Oct 2025. Responsibilities included developing a high-traffic travel date-picker component using React, writing automated tests using Jest, enhancing frontend performance with code splitting, and ensuring cross-browser compatibility and WCAG adherence. (Under Experience)\n\n------------------ Evaluation ------------------\n\n","output_type":"stream"},{"name":"stderr","text":"2025-12-01 05:50:40,332 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n2025-12-01 05:50:40,336 - INFO - Evaluating agent's answer...\n2025-12-01 05:50:40,337 - INFO - AFC is enabled with max remote calls: 10.\n","output_type":"stream"},{"name":"stdout","text":"Score: 10\n\nThe agent accurately and comprehensively lists the described work experiences from the resume, including roles, companies, dates, and key responsibilities. The answer is exceptionally clear, well-structured with bullet points, and directly addresses the question while remaining entirely grounded in the document's content.\nLast Question:\n What work experience does the resume describe?\n\nLast Agent Answer:\n The resume describes the following work experience:\n\n*   **Full Stack Developer Intern** at Codec Technologies, Pune, Maharashtra (Virtual) from Jan 2025 to Feb 2025. In this role, the individual engineered web solutions using the MERN Stack, built secure RESTful APIs with JWT Authentication and RBAC, optimized MongoDB queries, and collaborated on debugging issues using MVC architecture. (Under Experience)\n*   **Front-End Software Engineering Intern** at Skyscanner, Virtual from Sep 2025 to Oct 2025. Responsibilities included developing a high-traffic travel date-picker component using React, writing automated tests using Jest, enhancing frontend performance with code splitting, and ensuring cross-browser compatibility and WCAG adherence. (Under Experience)\n\n------------------ Evaluation ------------------\n\n","output_type":"stream"},{"name":"stderr","text":"2025-12-01 05:50:43,524 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n","output_type":"stream"},{"name":"stdout","text":"Score: 10\n\nThe agent's response accurately and comprehensively lists all work experience described in the resume. It is clearly structured with bullet points, bolding, and includes all relevant details like dates, roles, companies, and responsibilities. The answer directly addresses the question and is entirely grounded in the document's content.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def ask_agent(question: str):\n    \"\"\"\n    A helper function to manually ask questions to the agent.\n    Keeps memory and logs everything.\n    \"\"\"\n    global chat_history\n    logging.info(\"Manual question asked: %s\", question)\n\n    result = pdf_qa_agent(\n        question=question,\n        pdf_doc=pdf_part,\n        chat_history=chat_history\n    )\n    chat_history = result[\"updated_history\"]\n\n    print(\"\\nQ:\", question)\n    print(\"\\nAgent:\\n\", result[\"answer\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:50:43.532260Z","iopub.execute_input":"2025-12-01T05:50:43.532504Z","iopub.status.idle":"2025-12-01T05:50:43.539020Z","shell.execute_reply.started":"2025-12-01T05:50:43.532483Z","shell.execute_reply":"2025-12-01T05:50:43.537726Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"ask_agent(\"Explain my resume as if I am a beginner who doesn‚Äôt know technical terms.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:50:43.540235Z","iopub.execute_input":"2025-12-01T05:50:43.540571Z","iopub.status.idle":"2025-12-01T05:50:54.404735Z","shell.execute_reply.started":"2025-12-01T05:50:43.540541Z","shell.execute_reply":"2025-12-01T05:50:54.403817Z"}},"outputs":[{"name":"stderr","text":"2025-12-01 05:50:43,557 - INFO - Manual question asked: Explain my resume as if I am a beginner who doesn‚Äôt know technical terms.\n2025-12-01 05:50:43,558 - INFO - Agent received question: Explain my resume as if I am a beginner who doesn‚Äôt know technical terms.\n2025-12-01 05:50:43,559 - INFO - Building context from chat history with 6 messages.\n2025-12-01 05:50:43,560 - INFO - Calling Gemini model: gemini-2.5-flash\n2025-12-01 05:50:43,561 - INFO - AFC is enabled with max remote calls: 10.\n2025-12-01 05:50:54,398 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n2025-12-01 05:50:54,400 - INFO - Model returned an answer of length 2056 characters.\n","output_type":"stream"},{"name":"stdout","text":"\nQ: Explain my resume as if I am a beginner who doesn‚Äôt know technical terms.\n\nAgent:\n Here's a summary of the resume explained in simple terms for a beginner:\n\nThis resume is for someone who builds complete websites. They are skilled at creating both the parts you see and interact with (like buttons and text) and the hidden systems that make websites run smoothly behind the scenes.\n\n*   **What they're studying (Under Education):** They are currently pursuing a college degree in Computer Science and Engineering, which they expect to complete in June 2026. They have also finished their high school education.\n*   **Where they've gained work experience (Under Experience):**\n    *   At **Codec Technologies**, they helped build entire websites using a popular set of tools, making them faster to put online. They also set up secure ways to handle user data and made the website's information storage system work quicker.\n    *   At **Skyscanner**, they created a popular part of a travel website that many people use to pick dates. They wrote automatic checks to find mistakes early and made the website load faster for users, also making sure it worked well for everyone.\n*   **Examples of what they've built (Under Key Projects):** They designed a website for a restaurant that looks good and works well on phones, featuring engaging animations. They also built their own personal website to display their work, incorporating special visual effects.\n*   **Extra courses and learning (Under Certifications):** They've completed professional training courses in front-end development (the visible part of websites) and in problem-solving and leadership.\n*   **The tools and languages they use (Under Technical Skills):** They know several computer programming languages (like JavaScript and Python) and use various software tools and systems to build and manage websites and applications.\n*   **Their contributions to shared projects (Under Achievements):** They've actively contributed to public computer coding projects, making over 90 contributions in the last three months, which shows consistent engagement in building things online.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"ask_agent(\"What job roles am I most suitable for based on my resume?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:50:54.405978Z","iopub.execute_input":"2025-12-01T05:50:54.406315Z","iopub.status.idle":"2025-12-01T05:50:58.557959Z","shell.execute_reply.started":"2025-12-01T05:50:54.406285Z","shell.execute_reply":"2025-12-01T05:50:58.556955Z"}},"outputs":[{"name":"stderr","text":"2025-12-01 05:50:54,407 - INFO - Manual question asked: What job roles am I most suitable for based on my resume?\n2025-12-01 05:50:54,411 - INFO - Agent received question: What job roles am I most suitable for based on my resume?\n2025-12-01 05:50:54,412 - INFO - Building context from chat history with 8 messages.\n2025-12-01 05:50:54,413 - INFO - Calling Gemini model: gemini-2.5-flash\n2025-12-01 05:50:54,413 - INFO - AFC is enabled with max remote calls: 10.\n2025-12-01 05:50:58,550 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n2025-12-01 05:50:58,553 - INFO - Model returned an answer of length 293 characters.\n","output_type":"stream"},{"name":"stdout","text":"\nQ: What job roles am I most suitable for based on my resume?\n\nAgent:\n Based on your resume, you are most suitable for the following job roles:\n\n*   **Full Stack Developer** (As stated in your Professional Summary and experience at Codec Technologies)\n*   **Front-End Software Engineer/Developer** (As highlighted in your experience at Skyscanner and Key Projects)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# üìÑ Freestyle Track ‚Äì PDF Question-Answering Agent (AI Agents Intensive Capstone)\n\nThis project implements a **PDF Question-Answering Agent** using Google Gemini models.  \nThe agent reads a PDF (my resume) and answers questions based only on the content of that document.\n\n---\n\n# üéØ Goal of the Agent\nThe agent‚Äôs goal is to:\n- Load and analyze a PDF document.\n- Answer questions in natural language.\n- Stay grounded strictly in the PDF content.\n- Maintain memory across multiple questions.\n- Provide clear, structured responses.\n\n---\n\n# ü§ñ Key Agent Concepts Demonstrated\n\n## 1. **LLM-Powered Agent**\nThe core function `pdf_qa_agent()` uses a Gemini model as the reasoning engine.  \nThe agent understands queries, analyzes the PDF, and generates grounded answers.\n\n---\n\n## 2. **Custom Tool Usage**\nI implemented a **custom tool**:\n\n`load_pdf_tool(pdf_path)`\n\nThis tool:\n- Reads a PDF from Kaggle input directory.\n- Converts it into a Gemini-compatible `Part`.\n- Allows the agent to ‚Äúsee‚Äù and process the resume.\n\n---\n\n## 3. **Sequential Agent / Loop Behavior**\nThe agent handles multi-step interactions:\n- I asked 3 test questions in sequence.\n- The agent answered each one using the PDF.\n- The agent maintained memory across turns.\n\nThis demonstrates sequential agent workflow.\n\n---\n\n## 4. **Sessions & Memory**\nThe agent stores conversation turns using `chat_history`.  \nMemory is compacted (only the last few turns kept) to improve context efficiency.\n\nThis enables:\n- Follow-up questions\n- Multi-turn reasoning\n- Improved contextual grounding\n\n---\n\n## 5. **Observability (Logging)**\nI added Python `logging` to track:\n- When the agent receives questions\n- When the PDF loads\n- When the model is called\n- When answers are returned\n- When evaluations occur\n\nThis provides transparency into the agent‚Äôs execution.\n\n---\n\n## 6. **Agent Evaluation**\nThe function `evaluate_agent_answer()`:\n- Uses Gemini to evaluate the agent‚Äôs response\n- Scores the answer on accuracy, clarity, PDF grounding\n- Provides reasoning for the score\n\nThis satisfies the ‚ÄúAgent Evaluation‚Äù requirement.\n\n---\n\n# üìä Results\n- The agent successfully analyzed my resume.\n- It answered:  \n  - Summary  \n  - Skills  \n  - Work experience  \n- The evaluation gave the agent a **10/10 score**, indicating:\n  - High accuracy  \n  - Grounded responses  \n  - Clear structure  \n\n---\n\n# üöÄ Conclusion\n\nThis capstone demonstrates a complete **Freestyle AI Agent** applying key concepts taught in the Google √ó Kaggle 5-Day AI Agents Intensive Course:\n\n‚úîÔ∏è LLM agent  \n‚úîÔ∏è Tools (custom tool)  \n‚úîÔ∏è Memory  \n‚úîÔ∏è Sequential agent behavior  \n‚úîÔ∏è Observability (logging)  \n‚úîÔ∏è Agent evaluation  \n\nThe result is a functional, extendable PDF Q&A assistant that can be improved with features like RAG, multi-agent workflows, or a user interface.\n\n","metadata":{}}]}